---
permalink: /
title: "Welcome!"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---


I'm currently a postdoctoral fellow at the Institute for Foundations of Machine Learning (UT Austin). Previously, I was a research fellow at The Simons Institute for the Theory of Computing.  
I received my PhD from Massachusetts Institute of Technology, advised by Jonathan Kelner and Ronitt Rubinfeld. 

Before starting the PhD program, I completed my undergraduate studies at MIT with a major in Computer Science and a double minor in Physics and Philosophy. Earlier, I lived in Yerevan, Armenia, where I primarily competed in contests like the International Physics Olympiad (IPhO).

My scientific research interests include:
* Computational learning theory
* Computational statistics
* Distribution learning and testing

See [_this blog post_](https://www.let-all.com/blog/2025/07/21/testing-assumptions-of-learning-algorithms/), if you want to know more about some of my recent work.

Feel free to contact me via e-mail: MyFirstNameMyLastName at gmail.com

### Publications:

[_The Power of Iterative Filtering for Supervised Learning with (Heavy) Contamination_](https://arxiv.org/abs/2505.20177)\
Adam R. Klivans, Konstantinos Stavropoulos, Kevin Tian, Arsen Vasilyan\
39th Conference on Neural Information Processing Systems (**NeurIPS 2025**, to appear).\
**Accepted as a spotlight.**

[_Robust learning of halfspaces under log-concave marginals_](https://arxiv.org/abs/2505.13708)\
Jane Lange, Arsen Vasilyan\
39th Conference on Neural Information Processing Systems (**NeurIPS 2025**, to appear).\
**Accepted as a spotlight.**


[_Learning Constant-Depth Circuits in Malicious Noise Models_](https://raw.githubusercontent.com/mlresearch/v291/main/assets/klivans25a/klivans25a.pdf)\
Adam R. Klivans, Konstantinos Stavropoulos, Arsen Vasilyan\
38th Conference on Learning Theory (**COLT 2025**).


[_Local Lipschitz Filters for Bounded-Range Functions_](https://arxiv.org/abs/2308.14716)\
Jane Lange, Ephraim Linder, Sofya Raskhodnikova, Arsen Vasilyan\
ACM-SIAM Symposium on Discrete Algorithms  (**SODA 2025**).


[_Tolerant Algorithms for Learning with Arbitrary Covariate Shift_](https://arxiv.org/abs/2406.02742)\
Surbhi Goel, Abhishek Shetty, Konstantinos Stavropoulos, Arsen Vasilyan\
38th Conference on Neural Information Processing Systems (**NeurIPS 2024**).\
**Accepted as a spotlight.**


[_Efficient Discrepancy Testing for Learning with Distribution Shift_](https://arxiv.org/abs/2308.14716)\
Gautam Chandrasekaran, Adam R. Klivans, Vasilis Kontonis, Konstantinos Stavropoulos, Arsen Vasilyan\
38th Conference on Neural Information Processing Systems (**NeurIPS 2024**).

[_Plant-and-Steal: Truthful Fair Allocations via Predictions_](https://arxiv.org/abs/2308.14716)\
Ilan Reuven Cohen, Alon Eden, Talya Eden, Arsen Vasilyan\
38th Conference on Neural Information Processing Systems (**NeurIPS 2024**).

[_Learning Intersections of Halfspaces with Distribution Shift: Improved Algorithms and SQ Lower Bounds_](https://proceedings.mlr.press/v247/klivans24b.html)\
Adam R. Klivans, Konstantinos Stavropoulos, Arsen Vasilyan\
37th Conference on Learning Theory (**COLT 2024**).


[_Testable Learning with Distribution Shift_](https://proceedings.mlr.press/v247/klivans24a.html)\
Adam R. Klivans, Konstantinos Stavropoulos, Arsen Vasilyan\
37th Conference on Learning Theory (**COLT 2024**).


[_An Efficient Tester-Learner for Halfspaces_](https://arxiv.org/abs/2302.14853)\
Aravind Gollakota, Adam R. Klivans, Konstantinos Stavropoulos, Arsen Vasilyan\
12th International Conference on Learning Representations (**ICLR 2024**).

[_Tester-Learners for Halfspaces: Universal Algorithms_](https://arxiv.org/abs/2305.11765)\
Aravind Gollakota, Adam R. Klivans, Konstantinos Stavropoulos, Arsen Vasilyan\
37th Conference on Neural Information Processing Systems (**NeurIPS 2023**).\
**Accepted for oral presentation.**

[_Agnostic Proper Learning of Monotone Functions: Beyond the Black-box Correction Barrier_](https://ieeexplore.ieee.org/document/10353158)\
Jane Lange and Arsen Vasilyan\
64th IEEE Symposium on Foundations of Computer Science (**FOCS 2023**).\
**Invited to special issue.**

[_Testing Distributional Assumptions of Learning Algorithms_](https://dl.acm.org/doi/10.1145/3564246.3585117)\
Ronitt Rubinfeld, Arsen Vasilyan\
55th ACM Symposium on Theory of Computing (**STOC 2023**)

[_Properly Learning Monotone Functions via Local Reconstruction_](https://ieeexplore.ieee.org/document/9996614)\
Jane Lange, Ronitt Rubinfeld, Arsen Vasilyan\
63rd IEEE Symposium on Foundations of Computer Science (**FOCS 2022**)

[_Monotone Probability Distributions over the Boolean Cube Can Be Learned with Sublinear Samples_](https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.ITCS.2020.28)\
Ronitt Rubinfeld, Arsen Vasilyan\
11th Innovations in Theoretical Computer Science Conference (**ITCS 2020**)

[_Approximating the Noise Sensitivity of a Monotone Boolean Function_](https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.APPROX-RANDOM.2019.52)\
Ronitt Rubinfeld, Arsen Vasilyan\
Approximation, Randomization, and Combinatorial Optimization. Algorithms and Techniques\
(**APPROX/RANDOM 2019**).

### Doctoral thesis:
[_Enhancing Learning Algorithms via Sublinear-Time Methods_](https://vasilyan.net/files/vasilyan-phd-eecs-2024-thesis.pdf)\
Arsen Vasilyan, June 2024.









